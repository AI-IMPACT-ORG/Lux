\section{RG Flow and Computational Behavior}
\label{sec:rg-flow}

Having established the regulator framework in Section~\ref{sec:regularization}, we now develop the renormalization group machinery that reveals how these regulators evolve and how the computational process flows toward fixed points.

\paragraph{Hand-off from Section~\ref{sec:regularization}}
This section carries forward the following RG data from Section~\ref{sec:regularization}:
\begin{itemize}
\item \textbf{Regulator hierarchy} with scale parameter $\Lambda$ and grading parameters $\vec{q}$
\item \textbf{Normalization operator} $N$ and termination observable $\tau$
\item \textbf{Generating function} $\mathcal{G}(z,\bar{z};\vec{q},\Lambda)$ and correlator coefficients $\mathcal{Z}_{n,m}(\vec{q})$
\item \textbf{Moduli space} $\mathcal{M}$ of computational parameters
\end{itemize}

\paragraph{RG flow observables vs renormalization conditions}
We distinguish between:
\begin{itemize}
\item \textbf{RG flow observables} (evolve under RG): $\vec{q}_t$, $\mathcal{G}_t$, $\Lambda_t$, $\mathcal{Z}_{n,m}(\vec{q}_t)$
\item \textbf{Renormalization conditions} (fixed): $\tau$ (termination threshold), normalization scheme choices
\end{itemize}

The relationship between scale behavior and computational reversibility can be understood through how the scale parameter $\Lambda$ interacts with the three grading parameters $\vec{q} = (q_1, q_2, q_3)$ in our generating function from equation~\eqref{eq:generating-function}.

\subsection{RG Flow Behavior Classification}

\begin{definition}[RG Flow Behavior Classification]
\label{def:rg-flow-classification}
Fix a class $\mathcal{A}$ of \textbf{admissible observables} closed under encoders and RG flow. A computational system exhibits different behaviors under RG flow as the scale parameter $\Lambda$ varies:
\begin{align}
\text{Converging flow} &: \lim_{\Lambda \to \infty} \mathcal{O}(\Lambda) \text{ exists and is finite for all } \mathcal{O} \in \mathcal{A} \\
\text{Diverging flow} &: \lim_{\Lambda \to \infty} \mathcal{O}(\Lambda) \text{ diverges to infinity for some } \mathcal{O} \in \mathcal{A} \\
\text{Marginal flow} &: \lim_{\Lambda \to \infty} \mathcal{O}(\Lambda) \text{ oscillates, cycles, or exhibits other non-convergent behavior for some } \mathcal{O} \in \mathcal{A}
\end{align}
The classification is \textbf{relative to the admissible class $\mathcal{A}$} and independent of the specific choice of observable within this class.
\end{definition}

\subsection{RG Flow-Computational Correspondence}

\begin{theorem}[RG Flow-Computational Correspondence]
\label{thm:rg-computational-correspondence}
The relationship between RG flow behavior and computational properties can be described as:
\begin{align}
\text{Converging flow} &\leftrightarrow \text{Reversible computation} \quad (\text{information preserved}) \\
\text{Diverging flow} &\leftrightarrow \text{Irreversible computation} \quad (\text{information destroyed}) \\
\text{Marginal flow} &\leftrightarrow \text{Undecidable computation} \quad (\text{behavior cannot be determined})
\end{align}
\end{theorem}

The scale parameter $\Lambda$ determines computational reversibility through the RG flow behavior of our generating function. 

\begin{definition}[Information Monotone]
\label{def:information-monotone}
Define the \textbf{Shannon entropy} of the computational state distribution:
\[
S(\Lambda) = -\sum_{n,m} p_{n,m}(\Lambda) \log p_{n,m}(\Lambda), \quad p_{n,m}(\Lambda) = \frac{|\mathcal{Z}_{n,m}(\vec{q})|}{\sum_{n',m'} |\mathcal{Z}_{n',m'}(\vec{q})|}
\]
\end{definition}

\begin{theorem}[Entropy Monotonicity]
\label{thm:entropy-monotonicity}
Under RG flow, the entropy is non-increasing: $\frac{dS}{d\Lambda} \leq 0$. Equality holds if and only if the flow is \textbf{reversible} (converging RG flow).
\end{theorem}

This provides a natural definition of truth: a statement is true if and only if it corresponds to converging RG flow with zero entropy dissipation, meaning the computation preserves information and is reversible. This fundamental connection between RG flow and truth will be developed comprehensively in Section~\ref{sec:renormalization}.

\subsection{The General RG Flow Operator}

\begin{definition}[General RG Flow Operator]
\label{def:general-rg-operator}
Let $\mathcal{M}$ be the moduli space of computational parameters and $\mathcal{F}$ be the space of generating functions. The general RG flow operator is a family of maps:
\[
\mathcal{R}_t: \mathcal{F} \times \mathcal{M} \to \mathcal{F} \times \mathcal{M}
\]
parameterized by the RG time $t \in \mathbb{R}$, such that:
\begin{align}
\mathcal{R}_t(G, \vec{q}, \Lambda) &= (G_t, \vec{q}_t, \Lambda_t) \\
\mathcal{R}_0 &= \text{id} \\
\mathcal{R}_{t+s} &= \mathcal{R}_t \circ \mathcal{R}_s
\end{align}
where $G_t$ is the evolved generating function, $\vec{q}_t = (q_{1,t}, q_{2,t}, q_{3,t})$ are the running grading parameters, and $\Lambda_t$ is the running scale.
\end{definition}

\subsection{RG Flow Equations}

We write $t:=\log \Lambda$ (UV $t\to+\infty$); our convention is $d\Lambda/dt=\Lambda$.

\begin{definition}[RG Flow Equations]
\label{def:rg-flow-equations}
The RG flow is governed by the system of differential equations:
\begin{align}
\frac{d\mathcal{G}_t}{dt} &= \beta_{\mathcal{G}}(\mathcal{G}_t, \vec{q}_t, \Lambda_t) \\
\frac{d\vec{q}_t}{dt} &= \vec{\beta}_q(G_t, \vec{q}_t, \Lambda_t) \\
\frac{d\Lambda_t}{dt} &= \beta_\Lambda(G_t, \vec{q}_t, \Lambda_t)
\end{align}
where $\beta_{\mathcal{G}}$, $\vec{\beta}_q$, and $\beta_\Lambda$ are the beta functions for the generating function, grading parameters, and scale respectively.
\end{definition}

\subsection{Computational Beta Functions}

\begin{definition}[Computational Beta Functions]
\label{def:computational-beta-functions}
Introduce countable couplings $\{g_k\}_{k \in \mathbb{N}}$ where $g_k$ are (sparse) linear functionals of $\{\mathcal{Z}_{n,m}\}$. The beta functions encode how the computational structure evolves under RG flow:
\begin{align}
\frac{d\mathcal{G}}{dt} &= \sum_k \beta_k(\vec{g}) \frac{\partial \mathcal{G}}{\partial g_k}, \quad t = \log \Lambda \\
\vec{\beta}_q(\vec{g}) &= \left(\frac{dq_1}{dt}, \frac{dq_2}{dt}, \frac{dq_3}{dt}\right) \\
\beta_\Lambda(\vec{g}) &= \frac{d\Lambda}{dt} = \Lambda
\end{align}
The functional setting requires $\mathcal{Z} \in \ell^1$ (summable coefficients) and $\mathcal{G}$ linear in $\mathcal{Z}$. The beta functions depend on the computational paradigm through the grading parameters $\vec{q}$.
\end{definition}

\begin{definition}[Global observable]
\label{def:global-observable}
Fix $\vec{q}$. Define $\mathcal{O}(\Lambda):=\sum_{n,m\ge0}\mathcal{Z}_{n,m}(\vec{q})\,\Lambda^{-(n+m)}$.
Its beta-function is $\beta_\mathcal{O}(\Lambda):=\frac{d}{d\log\Lambda}\mathcal{O}(\Lambda)$.
\end{definition}

\begin{proposition}[Indicative RG–computational correspondence]
\label{prop:rg-corresp}
Assume $\mathcal{Z}_{n,m}\ge0$ and $\mathcal{R}_\Lambda$ decreases $(n+m)$-weight.
Then $\beta_\mathcal{O}\le0$ and convergence of $\mathcal{O}(\Lambda)$ implies
no information loss under the flow (reversible fragment).
\end{proposition}

\begin{conjecture}[Marginal flow and undecidability]
\label{conj:marginal}
Marginal behavior of $\mathcal{O}$ corresponds to boundary cases where halting cannot
be decided within the base fragment $\mathcal{L}_0$.
\end{conjecture}

\begin{example}[Synthetic RG Flow]
\label{ex:synthetic-rg-flow}
Consider a parameter $g$ in our type graph that drifts under coarse-graining. As $\Lambda$ increases, the observable $\mathcal{O}(\Lambda)$ evolves according to:
\[
\mathcal{O}(\Lambda) = g_0 \Lambda^{-\gamma} + \text{subleading terms}
\]
where $\gamma$ is the anomalous dimension. This gives $\beta(g) = -\gamma g$, showing how the parameter flows under RG evolution.
\end{example}

\subsection{Callan-Symanzik Equation as Trace}

\begin{theorem}[Callan-Symanzik as Trace]
\label{thm:callan-symanzik-trace}
The Callan-Symanzik equation emerges as a "trace" of the general RG flow operator:
\[
\left(\Lambda \frac{\partial}{\partial \Lambda} + \sum_{i=1}^3 \beta_i \frac{\partial}{\partial q_i} - \gamma\right) \mathcal{G}(z, \bar{z}; \vec{q}, \Lambda) = 0
\]
where $\gamma$ is the \textbf{anomalous dimension of the generating function} $\mathcal{G}$, arising from field rescaling counterterms. The sign convention follows standard CS form: $\gamma$ represents the scaling dimension shift due to renormalization. The beta functions $\beta_i$ are the traces of the corresponding RG flow components projected onto the $\{q_i, \Lambda\}$ subspace.
\end{theorem}

\subsection{RG Fixed Points and Universality Classes}

\begin{definition}[RG Fixed Points]
\label{def:rg-fixed-points}
An RG fixed point is where all beta functions vanish: $\beta_G = \vec{\beta}_q = \beta_\Lambda = 0$.
\end{definition}

\begin{definition}[Computational Universality Classes]
\label{def:computational-universality}
Systems belong to universality classes based on RG flow behavior:
\begin{itemize}
\item \textbf{Class I}: Converging RG flow (reversible computation)
\item \textbf{Class II}: Diverging RG flow (irreversible computation)  
\item \textbf{Class III}: Marginal RG flow (undecidable computation)
\end{itemize}
\end{definition}

\subsection{Speculative AGT Connection}

\begin{remark}[Speculative AGT Connection]
\label{rem:agt-consequence}
\textbf{[SPECULATIVE]} The AGT correspondence may appear as a consequence of the RG flow framework, with generating function structure extending to complex parameters and 4D gauge theory connections (Section~\ref{sec:boundary-maps}). This connection requires explicit construction of the functor $\mathcal{F}: \text{Computational RG} \to \text{AGT}$ and is not used in the main theorems.
\end{remark}

\subsection{Summary and Outlook}

This section established RG flow as a truth predicate for computation:

\begin{enumerate}
\item RG flow behavior classifies systems into three universality classes
\item Converging flow → reversible computation (truth)
\item Diverging flow → irreversible computation (falsehood)  
\item Marginal flow → undecidable computation
\end{enumerate}

The RG framework reveals deep connections between computation, information theory, and physics. The next section develops the complete renormalization procedure (Section~\ref{sec:renormalization}).

\textbf{Adapter back to §1}: the flow $(\Lambda,\vec{q},z,\bar{z})\mapsto (b\Lambda,\vec{q}(b),b^{-1}z,b^{-1}\bar{z})$ preserves the parameter map fixed in §1.