\section{Discussion}
\label{sec:discussion}

The results presented in this paper are in need of evaluation as they sketch concrete attempts at unifying several domains through their common root in logic. Even parts of it would represent a significant view on their respective domains. The most fundamental argument why the results here could be true is the systematic structure they promise - they show a world where basic principles of logic transform into concrete tools to use to understand reality. However, also a fundamentally different world where relationships between symbols are more important than the labels we use as humans to apply these insights across various domains. 

The fact that compiling code is presented is good, but considering that even moderately sized software projects tend to generate bugs should caution against claiming immediate victory. Indeed, in constructing these software artifacts bugs are a fact of life - that we cannot find any more does not definitively prove there are none left. Also, this then shows only syntactic soundness, not semantic soundness. In other words, if a particular domain map holds is a definite and pressing question. Supporting evidence by reproducing many known theorems is just that: supporting evidence. 

At minimum, the results in this paper could lead to renewed interest in the fundamental bounds on systems of logic, and what they imply. For instance, one way to use the results here is to show that the deformation of logic we introduced makes it possible to use Gödel, Tarski and related results as effective axioms in proof theory. The idea is that a large part of proving theorems may simply be boilerplate proving that Gödel and related bounds hold. This follows from their original derivation: encoding a logic into Peano Arithmetic through Gödel coding shows there is a representation of those constraints in single-sentence form. The pullback of these theorems to the original logic exists - its proof however may be very large. Similar comments apply actually to other theorems. One interesting use case of the technology discussed here is proof classification. 

This preceding paragraph has a special role in the making of this paper. In developing the results here often elaborate secondary proofs of parts of the framework in particular domains have been found, using a variety of supporting tools. However, as they were domain specific, they were taken as supporting evidence. Moreover, they tend to be considerably more complex than the logic-based approach presented here. In fact, even the minimal system presented here is not unique - there are other presentations emphasising different aspects of the framework. 

One observation made while working on this paper is the fundamental role logic plays in human language. For example: large language models are good at mathematical logic because human mathematicians basically use much of the same words and notation to express their thoughts in writing. This paper and its results is proof this leads to very strong coherence in large language models for this context. What is also true is that humans do not seem to understand logic naturally (present author included). We lack the basic words to talk about logic, resorting to homomorphisms to talk about "logic talking to itself", but also using arcane words to describe basic properties of logic and computation. Also natural language is more logical than one might think, but with an unstable choice of which formal system is used. For example: controlled natural languages are formal models of language that are surprisingly expressive. On the other hand, there are programming languages such as "Brainfuck" that are very logical, but also very different from natural language. 

The minimal family of system discussed here appears to be an essentially flat direction in the space of ideas as reflected in the training data of chatbots. Almost everything in this paper resonates with known results in the literature - logic is central to the training data. That leads to a behaviour of chatbots that is known as "sycophancy" - as it searches for the best possible response to a prompt, it simply constructs a combination of concepts that fits, bypassing most of the inference-time reasoning mechanisms designed to create more coherent responses. The responses start to depend much more crucially on the exact wording in the prompt, and the chatbot's outputs align much closer to the prompt than to the actual content of the training data. Chatbot responses also take noticeably more time when responding to general questions of pure logic, or to questions that hit many different research areas at the same time. 

The sycophancy effect is due to the stochastic nature of chatbots. It has no concept of truth beyond the training data. This paper proposes the use of automated checking tools to make sure results conform to some definition of truth. This paper shows a very particular way how to do this using off-the-shelf tooling, and proposes an even more streamlined way of including a ground truth. As a pattern, this can certainly be used to train better large language models. Another even more direct use is as a design pattern for large language model software components that adhere to some externally formulated policies, with a built-in syntactic verification loop. 

\section*{Outlook (Speculative)}
\label{sec:outlook}
\begin{notation}[AGT Mapping (Speculative)]
\label{not:agt-mapping}
Conditional identification of $\mathsf{Gen4}$ with conformal blocks under domain interpretation. Requires representation data (central charge, external/internal weights). Used only for intuition; not invoked in proofs.
\end{notation}
\begin{notation}[Hilbert--P\'olya Programme (Speculative)]
\label{not:hilbert-polya-programme}
Morphisms $\Phi^{HP}$ linking logic observables to operator algebras. States prerequisites (self-adjointness, trace-class conditions). No claims about RH; programme-level guidance only.
\end{notation}
\begin{notation}[P vs NP via Spectral Morphisms (Speculative)]
\label{not:p-vs-np-spectral}
$\Psi^{cl}$ framed as a transfer-operator programme. Presents one diagrammatic kernel/cokernel view; no claimed reductions beyond the logic's setting.
\end{notation}
